{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, date, timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_date(start=date(1400, 1, 1), end=date(2400, 1, 1)):\n",
    "    diff = end - start\n",
    "    return start + random.random() * diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_vector(xdate):\n",
    "    yr1 = xdate.year // 1000\n",
    "    yr2 = (xdate.year // 100) % 10\n",
    "    yr3 = (xdate.year // 10) % 10\n",
    "    yr4 = (xdate.year) % 10\n",
    "    \n",
    "    month = xdate.month\n",
    "    \n",
    "    day1 = xdate.day // 10\n",
    "    day2 = xdate.day % 10\n",
    "    \n",
    "    weekday = xdate.weekday()\n",
    "    \n",
    "    to_encode = [\n",
    "        (yr1, 10),\n",
    "        (yr2, 10),\n",
    "        (yr3, 10),\n",
    "        (yr4, 10),\n",
    "        (month, 12),\n",
    "        (day1, 10),\n",
    "        (day2, 10)\n",
    "    ]\n",
    "    \n",
    "    xs = []\n",
    "    for val, num_vals in to_encode:\n",
    "        one_hot = np.zeros(num_vals)\n",
    "        one_hot[val-1] = 1\n",
    "        xs.append(one_hot)\n",
    "        \n",
    "    x = np.concatenate(xs)\n",
    "    \n",
    "    y = np.zeros(7)\n",
    "    y[weekday] = 1\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding: One-hot, separate integers\n",
    "\n",
    "Training: Month, year, other years, other decades\n",
    "\n",
    "Raw\n",
    "\n",
    "Start small, build up\n",
    "\n",
    "One month, same month plus another, keep adding months until a year, then add new years\n",
    "One month, add a month, add a year, add several month, add several years, add decades\n",
    "Start without leap years, then include leap years\n",
    "\n",
    "Whole idea is to go simple and complex\n",
    "Introduce new concepts before past concepts are solidified\n",
    "Don't want to confuse things - easily possible\n",
    "\n",
    "Simplest would be a single month in non leap-year\n",
    "When introducing leap years, do half leap years and half non-leap years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(10*6 + 12,), activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def reset_model():\n",
    "    global model\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random(batch_size):\n",
    "    dates = []\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(batch_size):\n",
    "        rdate = rand_date()\n",
    "        x, y = convert_to_vector(rdate)\n",
    "        dates.append(rdate)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def get_range_gen(start_date, end_date):\n",
    "    def generate_range(batch_size):\n",
    "        dates = []\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for i in range(batch_size):\n",
    "            rdate = rand_date(start_date, end_date)\n",
    "            x, y = convert_to_vector(rdate)\n",
    "            dates.append(rdate)\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "        xs = np.array(xs)\n",
    "        ys = np.array(ys)\n",
    "        return xs, ys\n",
    "    return generate_range\n",
    "\n",
    "\n",
    "def get_month_gen(year, month):\n",
    "    start = date(year, month, 1)\n",
    "    if month == 12:\n",
    "        end = date(year + 1, 1, 1)\n",
    "    else:\n",
    "        end = date(year, month + 1, 1)\n",
    "    return get_range_generator(start, end)\n",
    "\n",
    "\n",
    "def combine_gens(generators, p=None):\n",
    "    if p is None:\n",
    "        p = [1/len(generators)] * len(generators)\n",
    "    \n",
    "    def generate(batch_size):\n",
    "        generator = np.random.choice(generators, p=p)\n",
    "        return generator(batch_size)\n",
    "    \n",
    "    return generate\n",
    "\n",
    "\n",
    "def get_months_gen(year, months, p=None):\n",
    "    gens = []\n",
    "    for month in months:\n",
    "        gens.append(get_month_generator(year, month))\n",
    "    return combine_generators(gens, p)\n",
    "\n",
    "\n",
    "def get_year_gen(year):\n",
    "    return get_range_generator(date(year, 1, 1), date(year+1, 1, 1))\n",
    "\n",
    "\n",
    "def get_years_gen(start_year, end_year):\n",
    "    return get_range_generator(date(start_year, 1, 1), date(end_year + 1, 1, 1))\n",
    "\n",
    "\n",
    "def get_years_gen_p(years, p=None):\n",
    "    gens = []\n",
    "    for year in years:\n",
    "        gens.append(get_year_generator(year))\n",
    "    return combine_generators(years, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_until_acc(model, data_gen, desired_acc, output=True, limit=1000000):\n",
    "    running_acc = 0\n",
    "    num_samples = 0\n",
    "    batch_size = 32\n",
    "    accs = deque(maxlen=10)\n",
    "    accs.append(desired_acc-0.01) # so we don't get the divide by zero error\n",
    "    \n",
    "    batch_num = 0\n",
    "    while sum(accs)/len(accs) < desired_acc:\n",
    "        xs, ys = data_gen(batch_size)\n",
    "        loss, acc = model.train_on_batch(xs, ys)\n",
    "        accs.append(acc)\n",
    "        num_samples += batch_size\n",
    "        batch_num += 1\n",
    "        if batch_num % 100 == 0:\n",
    "            print(\"Minibatch\", batch_num, sum(accs)/len(accs))\n",
    "        if num_samples > limit: # 1 mil by default\n",
    "            break\n",
    "    return num_samples\n",
    "\n",
    "\n",
    "def run_schedule(schedule):\n",
    "    reset_model()\n",
    "    \n",
    "    total_samples = 0\n",
    "    for name, data_gen, accuracy in schedule:\n",
    "        num_samples = train_until_acc(model, data_gen, accuracy)\n",
    "        total_samples += num_samples\n",
    "        print('Trained {} in {} samples'.format(name, num_samples))\n",
    "    print('Training complete after {} samples'.format(total_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def get_schedule_generator(x):\n",
    "    class P:\n",
    "        def __init__(self, x):\n",
    "            self.x = x\n",
    "        def __getitem__(self, key):\n",
    "            x.add_constraints()\n",
    "            return softmax(x[key])\n",
    "    \n",
    "    x = X(x)\n",
    "    p = P(x)\n",
    "    \n",
    "    schedule = [\n",
    "        ('Aug', get_month_generator(2019, 8), 0.99)\n",
    "    ]\n",
    "    class StagedValue:\n",
    "        def __init__(self, num):\n",
    "            self.num = num\n",
    "    class Stager:\n",
    "        def __init__(self):\n",
    "            self.total = 0\n",
    "            self.constraints = []\n",
    "        def __getitem__(self, key):\n",
    "            self.total += key\n",
    "            new_constraints = None # TODO Implement new constraints\n",
    "            self.constraints.append(new_constraints)\n",
    "            return StagedValue(key)\n",
    "    \n",
    "    # TODO How do I get this for multiple situations\n",
    "    schedule = [ # Have a schedule generator. Maybe iterate through after staging to activate\n",
    "        ('Aug', get_month_generator(2019, 8), 0.99),\n",
    "        ('Sep', get_months_generator(2019, [8, 9], p=p[2]), 0.99),\n",
    "        ('All', get_month_generator(2019, [8, 9]), 0.99)\n",
    "    ]\n",
    "    \n",
    "    # need to create function that accepts the right number of parameters and stuff\n",
    "    # use sparse matrix to represent constraints\n",
    "    class X:\n",
    "        def __init__(self, x):\n",
    "            self.x = x\n",
    "            self.current = 0\n",
    "        def __getitem__(self, key):\n",
    "            values = self.x[self.current: self.current+key]\n",
    "            self.current += key\n",
    "            return values\n",
    "        def __len__(self):\n",
    "            return self.current\n",
    "        \n",
    "    def get_schedule(x):\n",
    "        x = X(x)\n",
    "        processed_schedule = []\n",
    "        for name, func, params, probability in schedule:\n",
    "            # process into actual schedule\n",
    "            new_params = []\n",
    "            for param in params:\n",
    "                if type(param) is StagedValue:\n",
    "                    new_params.append(x[param.num])\n",
    "                else:\n",
    "                    new_params.append(param)\n",
    "            schedule_item = (name, func(*params), probability)\n",
    "            processed_schedule.append(schedule_item)\n",
    "        return processed_schedule\n",
    "    \n",
    "    return get_schedule, constraints, x0\n",
    "    \n",
    "    \n",
    "    \n",
    "    schedule = [ # Have a schedule generator. Maybe iterate through after staging to activate\n",
    "        ('Aug', get_month_generator(2019, 8), 0.99),\n",
    "        ('Sep', get_months_generator(2019, [8, 9], p=p[2]), x[1]),\n",
    "        ('Oct', get_month_generator(2019, [8, 9, 10], p=p[3]), x[1]),\n",
    "        ('Oct', get_month_generator(2019, [8, 9, 10]), 0.99)\n",
    "    ]\n",
    "    \n",
    "    schedule = [\n",
    "        ('2019-1', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-2', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-3', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-4', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-5', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-6', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-7', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-8', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-9', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-10', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-11', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019-12', get_months_gen(2019, range(1, 13), p=x[12]), x[1]),\n",
    "        ('2019', get_year_generator(2019), 0.99),\n",
    "#         ('2020', get_years_gen(2019, 2020), x[1]),\n",
    "#         ('2020s', get_years_gen(2019, 2029), x[1]),\n",
    "#         ('2000-2100', get_years_gen(2000, 2100), x[1]),\n",
    "#         ('1900-2100', get_years_gen(1900, 2100), x[1]),\n",
    "#         ('1-2100', get_years_gen(1, 2100), x[1]),\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    return schedule, len(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the last two, so the new one and the most recent before that. That way, there's a lag time, but most of it is set. We can also save the progresss of the model to make the running occur faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_years_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-df03995773a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'Jun'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_months_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2019\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.85\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'2019'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_year_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2019\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.85\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[1;34m'2020'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_years_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2019\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2020\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.85\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'2020s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_years_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2019\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2029\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.85\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'2000-2100'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_years_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.85\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_years_gen' is not defined"
     ]
    }
   ],
   "source": [
    "schedule = [\n",
    "    ('Jul', get_months_gen(2019, [7]), 0.99),\n",
    "    ('Aug', get_months_gen(2019, [8]), 0.85),\n",
    "    ('Sep', get_months_gen(2019, [9]), 0.85),\n",
    "    ('Oct', get_months_gen(2019, [10]), 0.85),\n",
    "    ('Nov', get_months_gen(2019, [11]), 0.85),\n",
    "    ('Dec', get_months_gen(2019, [12]), 0.85),\n",
    "    ('Jan', get_months_gen(2019, [1]), 0.85),\n",
    "    ('Feb', get_months_gen(2019, [2]), 0.85),\n",
    "    ('Mar', get_months_gen(2019, [3]), 0.85),\n",
    "    ('Apr', get_months_gen(2019, [4]), 0.85),\n",
    "    ('May', get_months_gen(2019, [5]), 0.85),\n",
    "    ('Jun', get_months_gen(2019, [6]), 0.85),\n",
    "    ('2019', get_year_generator(2019), 0.85),\n",
    "    ('2020', get_years_gen(2019, 2020), 0.85),\n",
    "    ('2020s', get_years_gen(2019, 2029), 0.85),\n",
    "    ('2000-2100', get_years_gen(2000, 2100), 0.85),\n",
    "    ('1900-2100', get_years_gen(1900, 2100), 0.85),\n",
    "    ('1-2100', get_years_gen(1, 2100), 0.85),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_schedule(schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch 100 0.5375\n",
      "Trained July in 6208 samples\n",
      "Trained Aug in 3072 samples\n",
      "Trained Sep in 32 samples\n",
      "Minibatch 100 0.571875\n",
      "Trained Oct in 6016 samples\n",
      "Trained Nov in 32 samples\n",
      "Trained Dec in 64 samples\n",
      "Trained Jan in 32 samples\n",
      "Minibatch 100 0.79375\n",
      "Trained Feb in 3328 samples\n",
      "Trained Mar in 64 samples\n",
      "Trained Apr in 32 samples\n",
      "Trained May in 32 samples\n",
      "Trained Jun in 1568 samples\n",
      "Trained Jul-Dec in 32 samples\n",
      "Trained 2019 in 3008 samples\n",
      "Minibatch 100 0.75\n",
      "Trained 2020 in 5312 samples\n",
      "Minibatch 100 0.584375\n",
      "Minibatch 200 0.778125\n",
      "Minibatch 300 0.79375\n",
      "Trained 2020s in 9856 samples\n",
      "Minibatch 100 0.509375\n",
      "Minibatch 200 0.6625\n",
      "Minibatch 300 0.6875\n",
      "Minibatch 400 0.75625\n",
      "Minibatch 500 0.796875\n",
      "Minibatch 600 0.7875\n",
      "Trained 2000-2100 in 19904 samples\n",
      "Trained 1900-2100 in 2944 samples\n",
      "Minibatch 100 0.45625\n",
      "Minibatch 200 0.5125\n",
      "Minibatch 300 0.6125\n",
      "Minibatch 400 0.65\n",
      "Minibatch 500 0.65625\n",
      "Minibatch 600 0.68125\n",
      "Minibatch 700 0.696875\n",
      "Minibatch 800 0.721875\n",
      "Minibatch 900 0.734375\n",
      "Minibatch 1000 0.746875\n",
      "Minibatch 1100 0.778125\n",
      "Minibatch 1200 0.80625\n",
      "Minibatch 1300 0.825\n",
      "Trained 1-2100 in 42400 samples\n",
      "Minibatch 100 0.815625\n",
      "Minibatch 200 0.85625\n",
      "Minibatch 300 0.85625\n",
      "Minibatch 400 0.884375\n",
      "Minibatch 500 0.853125\n",
      "Minibatch 600 0.85\n",
      "Minibatch 700 0.890625\n",
      "Minibatch 800 0.9\n",
      "Minibatch 900 0.90625\n",
      "Minibatch 1000 0.90625\n",
      "Minibatch 1100 0.884375\n",
      "Minibatch 1200 0.925\n",
      "Minibatch 1300 0.940625\n",
      "Minibatch 1400 0.925\n",
      "Minibatch 1500 0.946875\n",
      "Minibatch 1600 0.9375\n",
      "Minibatch 1700 0.94375\n",
      "Minibatch 1800 0.965625\n",
      "Minibatch 1900 0.95\n",
      "Minibatch 2000 0.953125\n",
      "Minibatch 2100 0.928125\n",
      "Minibatch 2200 0.940625\n",
      "Minibatch 2300 0.959375\n",
      "Minibatch 2400 0.9625\n",
      "Minibatch 2500 0.959375\n",
      "Minibatch 2600 0.96875\n",
      "Minibatch 2700 0.971875\n",
      "Minibatch 2800 0.96875\n",
      "Minibatch 2900 0.971875\n",
      "Minibatch 3000 0.971875\n",
      "Minibatch 3100 0.9625\n",
      "Minibatch 3200 0.984375\n",
      "Minibatch 3300 0.946875\n",
      "Minibatch 3400 0.95\n",
      "Minibatch 3500 0.978125\n",
      "Minibatch 3600 0.975\n",
      "Minibatch 3700 0.98125\n",
      "Minibatch 3800 0.975\n",
      "Minibatch 3900 0.98125\n",
      "Minibatch 4000 0.98125\n",
      "Minibatch 4100 0.990625\n",
      "Minibatch 4200 0.990625\n",
      "Minibatch 4300 0.978125\n",
      "Trained 1-2100 in 138720 samples\n",
      "Training complete after 242656 samples\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "reset_model()\n",
    "\n",
    "schedule = [\n",
    "    ('July', get_month_generator(2019, 7), 0.85),\n",
    "    ('Aug', get_months_gen(2019, range(7, 9)), 0.85),\n",
    "    ('Sep', get_months_gen(2019, range(7, 10)), 0.85),\n",
    "    ('Oct', get_months_gen(2019, range(7, 11)), 0.85),\n",
    "    ('Nov', get_months_gen(2019, range(7, 12)), 0.85),\n",
    "    ('Dec', get_months_gen(2019, range(7, 13)), 0.85),\n",
    "    ('Jan', get_months_gen(2019, chain(range(1, 2), range(7, 13))), 0.85),\n",
    "    ('Feb', get_months_gen(2019, chain(range(1, 3), range(7, 13))), 0.85),\n",
    "    ('Mar', get_months_gen(2019, chain(range(1, 4), range(7, 13))), 0.85),\n",
    "    ('Apr', get_months_gen(2019, chain(range(1, 5), range(7, 13))), 0.85),\n",
    "    ('May', get_months_gen(2019, chain(range(1, 6), range(7, 13))), 0.85),\n",
    "    ('Jun', get_months_gen(2019, chain(range(1, 7), range(7, 13))), 0.85),\n",
    "    ('Jul-Dec', get_months_gen(2019, chain(range(1, 8), range(7, 13))), 0.85),\n",
    "    ('2019', get_year_generator(2019), 0.85),\n",
    "    ('2020', get_years_gen(2019, 2020), 0.85),\n",
    "    ('2020s', get_years_gen(2019, 2029), 0.85),\n",
    "    ('2000-2100', get_years_gen(2000, 2100), 0.85),\n",
    "    ('1900-2100', get_years_gen(1900, 2100), 0.85),\n",
    "    ('1-2100', get_years_gen(1, 2100), 0.85),\n",
    "    ('1-2100', get_years_gen(1, 2100), 0.999),\n",
    "]\n",
    "\n",
    "bad_schedule = [\n",
    "    ('1-2100', get_years_gen(1, 2100), 0.85)\n",
    "]\n",
    "\n",
    "schedule_2 = list(map(lambda item: (item[0], item[1], 0.5), schedule))\n",
    "schedule_2[-1] = schedule[-1]\n",
    "\n",
    "schedule_3 = list(map(lambda item: (item[0], item[1], 0.2), schedule))\n",
    "schedule_3[-1] = schedule[-1]\n",
    "\n",
    "run_schedule(schedule)\n",
    "\n",
    "# print('\\n\\n\\n')\n",
    "# reset_model()\n",
    "# run_schedule(model, schedule_2)\n",
    "# print('\\n\\n\\n')\n",
    "# reset_model()\n",
    "# run_schedule(model, schedule_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_vector(date(2019,7,28))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.21856205e-04, 4.16064868e-04, 3.76252714e-03, 1.97594166e-02,\n",
       "        8.88420641e-01, 7.28261918e-02, 1.44934375e-02]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(convert_to_vector(date(2035,5,18))[0].reshape((1, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, it seems that a model with 0.85 threshold trains with 160k samples and a model with 0.5 threshold trains with 120k samples.\n",
    "\n",
    "I tested a model with no grading. It got 100k batches (3,200k samples) without having improved its' accuracy at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we train some type of model that takes in training histories and outputs the ideal training history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100000/100000 [==============================] - 19s 190us/step - loss: 0.4153 - acc: 0.8324\n"
     ]
    }
   ],
   "source": [
    "stuff = model.fit(xs, ys)\n",
    "\n",
    "stuff\n",
    "print(stuff.history['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "\n",
    "- Overfit on a single sample of say 1000, then as soon as its' prediction is better than chance, move along to another set. \n",
    "  - Compare to pure random\n",
    "- Overfit on a sample of just a few, and then start throwing in new ones? - This was the whole strategy from before\n",
    "  - This would work, but we want our sample to be better than just chance, how do we determine the sample?\n",
    "\n",
    "1. Just do in order with random distributions up until a certain threshold\n",
    "  - Test different thresholds for progression, 50% accuracy, 90%, etc\n",
    "2. Change distribution to reflect the learning that needs to happen\n",
    "  - If you get a certain month right 90% of the time, only show it 10% of the time or something like that - determine this distrubtion\n",
    "3. Learn the distribution using some kind of statistics or model\n",
    "4. Create an ml model that perfects this situation\n",
    "\n",
    "Also, should be considering taking a month where we know the date and asking for another date. So if we know that today is the 18th and a Thursday, we can infer that tomorrow is the 19th and a Friday."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
